{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rafae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from Functions.documents import load_documents\n",
    "from Functions.text import clear_text, remove_stopwords, split_text_into_chunks, remove_portuguese_accents\n",
    "\n",
    "\n",
    "\n",
    "DOCUMENT_PATHS = [\"./Documents/a (1).pdf\", \"./Documents/FAQ (1).pdf\"]\n",
    "CHUNK_SIZE = 500\n",
    "\n",
    "\n",
    "\n",
    "# BEGIN = Processing documents \n",
    "texts = load_documents(DOCUMENT_PATHS)\n",
    "cleaned_texts = [clear_text(text) for text in texts]\n",
    "no_stopwords_text = [remove_stopwords(text) for text in cleaned_texts]\n",
    "no_accents_portuguese = [remove_portuguese_accents(text) for text in no_stopwords_text]\n",
    "joined_texts = \" \".join(no_accents_portuguese)\n",
    "joined_texts = joined_texts.lower()\n",
    "text_chunks = split_text_into_chunks(joined_texts, chunk_size=CHUNK_SIZE)\n",
    "# END = Processing documents \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3894"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\rafae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\rafae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from Functions.documents import load_documents\n",
    "from Functions.text import clear_text, remove_stopwords, split_text_into_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rafae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = model.encode(text_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_encoded = text_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3894"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_embeddings = [model.encode(chunk) for chunk in text_chunks] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_embedding = model.encode(\"Como e quando posso realizar o trancamento de matrícula?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5742928385734558, 0.530009925365448, 0.4637027382850647, 0.6362056136131287, 0.5164728164672852, 0.5483729243278503, 0.5802350044250488, 0.6583434045314789, 0.6417689025402069, 0.5609636306762695, 0.6662200391292572, 0.6107828915119171, 0.6246375143527985, 0.6299183368682861, 0.5671376883983612, 0.526781439781189, 0.6537935137748718, 0.5203404426574707, 0.6117911636829376, 0.6069388389587402, 0.5793417096138, 0.5098774135112762]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "# Compute cosine similarity between the question and all document chunks\n",
    "cosine_similarities = [util.pytorch_cos_sim(question_embedding, doc_emb).item() for doc_emb in document_embeddings]\n",
    "\n",
    "# Convert cosine similarity to a distance measure (1 - similarity)\n",
    "cosine_distances = [1 - sim for sim in cosine_similarities]\n",
    "\n",
    "print(cosine_distances)  # List of distances (lower means more similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant document chunk index: 2 (Score: 0.5362972617149353)\n",
      "Least relevant document chunk index: 10 (Score: 0.3337799608707428)\n"
     ]
    }
   ],
   "source": [
    "# Find the index of the most similar (highest similarity) and least similar (lowest similarity) document chunks\n",
    "max_index = max(range(len(cosine_similarities)), key=lambda i: cosine_similarities[i])\n",
    "min_index = min(range(len(cosine_similarities)), key=lambda i: cosine_similarities[i])\n",
    "\n",
    "print(f\"Most relevant document chunk index: {max_index} (Score: {cosine_similarities[max_index]})\")\n",
    "print(f\"Least relevant document chunk index: {min_index} (Score: {cosine_similarities[min_index]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x disposicoes finais transitorias 43 glossario 45 8 capitulo i matricula secao i concessao matricula art 1º matricula concedida i candidato classificado processo seletivo adotado universidade periodo letivo obteve classificacao reclassificacao ii estudante credenciado convenio instituicoes nacionais estrangeiras convenio intercambio acordo cultural brasil outros paises iii estudante admitido estudante especial iv estudante transferido ex officio v estudante transferido cursos ufba outras ies secao ii efetivacao matricula art 2º candidato procurador legalmente constituido efetuara matricula local periodo fixados edital especifico convocacao classificados processo seletivo sob pena perda direito art 3º matricula compreendera i apresentacao entrega documentos ii inscricao componentes curriculares curriculo curso 1º documentacao incompleta dara direito matricula universidade 2º oriundo pais estrangeiro certificado conclusao diploma graduacao pos graduacao historico escolar equivalente deverao revalidados autenticados autoridade consular brasil pais emitiu acompanhados traducao oficial 3o candidato classificado processo seletivo sido estudante regular graduacao pos graduacao ufba concorrido reserva vagas exigidos todos documentos exceto certificado conclusao ensino medio diploma graduacao substituidos historico escolar expedidos universidade art 4º candidato classificado reclassificado processo seletivo apresentar dentro prazos estabelecidos documentacao exigida edital processo seletivo perdera direito vaga universidade art 5º constatada qualquer tempo falsidade irregularidade insanavel documentacao apresentada matricula verificando efetivamente estudante direito ufba procedera cancelamento mesma prejuizo demais acoes cabiveis 9 art 6º candidato admitido matricula encaminhado servico medico universidade submeter exames obrigatorios subsecao i inscricao semestral componentes curriculares art 7º inscricao componentes curriculares reservada estudante regularmente matriculado universidade comprovada identidade procurador realizada base estrutura curricular curso acordo etapas periodos definidos calendario agenda academica 1º estudante graduacao podera inscrever componentes curriculares integrem curriculo curso respeitado limite maximo quatrocentas oito 408 horas enquanto estudante regular universidade 2º estudante graduacao pos graduacao podera inscrever componentes curriculares outro nivel mediante solicitacao oferta vagas departamento equivalente art 8o colegiado curso estabelecera etapa orientacao estudantes precedera inscricao componentes curriculares art 9o criterios escalonamento comuns todos cursos graduacao serem aplicados inscricao semestral estudantes componentes curriculares definidos instrucao normativa especifica aprovada conselho art 10 inscricao semestral componentes curriculares graduacao efetivada atendendo limites minimo cento duas 102 horas semestrais maximo seiscentos doze 612 horas semestrais s pre requisito s s co requisito s componentes curriculares sendo permitida superposicao parcial total horarios componentes selecionados 1º coordenador colegiado curso podera autorizar inscricao semestral componentes curriculares abaixo limite minimo acima limite maximo carga horaria semanal definida caput deste artigo mediante justificativa estudante observando obrigatoriamente tempos minimo maximo conclusao curso determinados legislacao 2º inclui limite maximo refere caput deste artigo inscricao estagios curriculares internatos trabalhos conclusao cursos recitais conclusao cursos monografias atividades semelhantes exigidas integralizacao curriculos art 11 colegiado curso podera conceder estudante direito cursar componentes curriculares paralelo pre requisito 1º cinco 05 dias apos conclusao periodo inscricao componentes curriculares coordenacao atendimento registros estudantis care disponibilizara colegiados relacao estudantes paralelismo ausencia pre requisito co requisito 10 2º decorridos vinte cinco cento 25 semestre letivo coordenador colegiado lancara sistema informatizado registro controle academico institucional universidade confirmacao correcao inscricao disciplinas registro data aprovacao decisao plenaria colegiado art 12 cursos oferecam modalidade habilitacao opcao devera observado segue i estudante matriculado\n"
     ]
    }
   ],
   "source": [
    "print(text_chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monge:  0.034999999999999996\n",
      "cosine:  0.6149186938124421\n",
      "hamming:  0.09999999999999998\n"
     ]
    }
   ],
   "source": [
    "import textdistance\n",
    "# https://github.com/life4/textdistance?tab=readme-ov-file\n",
    "\n",
    "f1 = \"o carro está andando\"\n",
    "# f2 = \"o ônibus está em movimento\"\n",
    "f2 = \"o ônibus andando\"\n",
    "print(\"monge: \",textdistance.monge_elkan(f1,f2))\n",
    "print(\"cosine: \",textdistance.cosine(f1,f2))\n",
    "print(\"hamming: \",textdistance.hamming.normalized_similarity(f1,f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute cosine similarity between the question and all document chunks\n",
    "cosine_similarities = [util.pytorch_cos_sim(self.query_embedding, doc_emb).item() for doc_emb in self.document_embeddings]\n",
    "\n",
    "# Convert cosine similarity to a distance measure (1 - similarity)\n",
    "cosine_distances = [1 - sim for sim in cosine_similarities]\n",
    "\n",
    "self.similarities = np.array(cosine_distances.copy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
